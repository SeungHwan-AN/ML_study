Aeq2 %*% target <= Aeq4 + Aeq5 %*% target,
Aeq2 %*% target >= Aeq4 - Aeq5 %*% target,
Aeq1 %*% target >= 0)
objective = Minimize(Aeq1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
# result
target = result$getValue(target)
rho_min = target[1, ]
z = target[2:(1+p), ,drop=F]
lambda = target[(p+2):nrow(target), ,drop=F]
rho_min; z; lambda
t(Aeq)
### 1. 이건 경계에 있는 predictor를 바로 activeset 지정 -> 이건 아닌듯!
idx1 = which(abs((-t(X) %*% y + rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
idx2 = which(abs((-t(X) %*% y - rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
activeset = union(idx1, idx2)
sort(activeset)
# rho_min에서는 모든 부등조건을 만족
idx1 = which((-t(X) %*% y + rho_min * one_p) <= t(Aeq) %*% lambda)
idx2 = which((-t(X) %*% y - rho_min * one_p) >= t(Aeq) %*% lambda)
activeset = c(idx1, idx2)
sort(activeset)
### 2. violation check
# find new_lambda corresponding to decreased rho(아주 작게 감소된 rho에 대해 violation을 새로 체크)
new_rho = rho_min - 1e-4 # rho is decreasing direction
target = Variable(1 + m)
Amat1 = matrix(c(rep(0, m), 1), nrow = 1)
Amat = rbind(cbind(t(Aeq), one_p), cbind(-t(Aeq), one_p))
bmat = rbind(-t(X) %*% y + 2 * new_rho * one_p, t(X) %*% y + 2 * new_rho * one_p)
constraints = list(Amat %*% target <= bmat,
Amat1 %*% target <= new_rho)
objective = Maximize(Amat1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
z = result$getValue(target)[m+1, ]
new_lambda = result$getValue(target)[1:m, , drop=F]
# 새로운 rho, lambda에 대해 부등조건을 만족하지 않는(범위를 벗어나는) predictor를 찾는다
idx1 = which((-t(X) %*% y + new_rho * one_p) <= t(Aeq) %*% new_lambda)
idx2 = which((-t(X) %*% y - new_rho * one_p) >= t(Aeq) %*% new_lambda)
activeset = c(idx1, idx2)
sort(activeset) # 최종 active set
# 3. linear combination
activeset = c()
for(i in 1:m) {
idx1 = which(abs(((-t(X) %*% y + rho_min * one_p) - t(Aeq)[, -i, drop=F] %*%
lambda[-i, ,drop=F]) / t(Aeq)[, i] - lambda[i, ]) < 1e-4)
idx2 = which(abs(((-t(X) %*% y - rho_min * one_p) - t(Aeq)[, -i, drop=F] %*%
lambda[-i, ,drop=F]) / t(Aeq)[, i] - lambda[i, ]) < 1e-4)
# print(c(idx1, idx2))
# if(length(activeset) > 0) activeset = c(idx1, idx2)
# activeset = intersect(activeset, c(idx1, idx2))
activeset = union(activeset, c(idx1, idx2))
}
activeset
sort(activeset)
rm(list=ls())
gc()
set.seed(520)
if(!require("CVXR")) install.packages("CVXR")
library("CVXR")
# setting
n = 100
p = 5
m = 2
# data
X = matrix(rnorm(n*p), nrow = n)
X.m = apply(X, 2, mean)
X.m = matrix(X.m, nrow = n, ncol = p, byrow = T)
X = X - X.m
true_b = rep(1, p)
y = X %*% true_b + rnorm(n)
y = y - mean(y)
# constraints
# Aeq = matrix(sample(seq(-1, 2, by = 1), m * p, replace = T), nrow = m)
Aeq = matrix(sample(c(-2, -1, 1, 2), m * p, replace = T), nrow = m)
# Aeq = matrix(c(1,1,0,
# -1,0,1,
# -1,-1,1), nrow = m, byrow = T)
beq = matrix(rep(0, m), nrow = m)
# setting
zero_p = matrix(rep(0, p), ncol = 1)
zero_m = matrix(rep(0, m), ncol = 1)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
one_p = matrix(rep(1, p), ncol = 1)
one_m = matrix(rep(1, m), ncol = 1)
I_p = matrix(diag(rep(1, p)), nrow = p)
# design matrix for Constraints
Aeq1 = matrix(c(1, t(zero_p), t(zero_m)), nrow = 1)
Aeq2 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, I_p, zero_pm),
c(0, t(zero_p), t(zero_m)))
Aeq3 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, zero_pp, t(Aeq)),
c(0, t(zero_p), t(zero_m)))
Aeq4 = rbind(0, -t(X)%*%y, 0)
Aeq5 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(one_p, zero_pp, zero_pm),
c(0, t(zero_p), t(zero_m)))
# solve
target = Variable(1 + p + m)
constraints = list(Aeq2 %*% target == Aeq3 %*% target,
Aeq2 %*% target <= Aeq4 + Aeq5 %*% target,
Aeq2 %*% target >= Aeq4 - Aeq5 %*% target,
Aeq1 %*% target >= 0)
objective = Minimize(Aeq1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
# result
target = result$getValue(target)
rho_min = target[1, ]
z = target[2:(1+p), ,drop=F]
lambda = target[(p+2):nrow(target), ,drop=F]
rho_min; z; lambda
t(Aeq)
idx1 = which(abs((-t(X) %*% y + rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
idx2 = which(abs((-t(X) %*% y - rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
activeset = union(idx1, idx2)
sort(activeset)
# plot
l1 = seq(-100, 200, length.out = 1000)
l2 = seq(-100, 200, length.out = 1000)
# rho_min = rho_min - 100
y_plus = function(l1, i) (-t(X) %*% y + rho_min * one_p)[i, ] / t(Aeq)[i ,2] - (l1 * t(Aeq)[i ,1]) / t(Aeq)[i ,2]
y_minus = function(l1, i) (-t(X) %*% y - rho_min * one_p)[i, ] / t(Aeq)[i ,2] - (l1 * t(Aeq)[i ,1]) / t(Aeq)[i ,2]
plot(l1, l2, ylab = "", type = "n", col = 1)
points(lambda[1, ], lambda[2, ], col = p+1)
for(i in 1:p) lines(l1, y_plus(l1, i), ylab = "", col = i)
for(i in 1:p) lines(l1, y_minus(l1, i), ylab = "", col = i)
rm(list=ls())
gc()
set.seed(520)
if(!require("CVXR")) install.packages("CVXR")
library("CVXR")
# setting
n = 200
p = 10
m = 5
# data
X = matrix(rnorm(n*p), nrow = n)
X.m = apply(X, 2, mean)
X.m = matrix(X.m, nrow = n, ncol = p, byrow = T)
X = X - X.m
true_b = rep(1, p)
y = X %*% true_b + rnorm(n)
y = y - mean(y)
# constraints
Aeq = matrix(sample(seq(-1, 2, by = 1), m * p, replace = T), nrow = m)
# Aeq = matrix(sample(c(-2, -1, 1, 2), m * p, replace = T), nrow = m)
# Aeq = matrix(c(1,1,0,
# -1,0,1,
# -1,-1,1), nrow = m, byrow = T)
beq = matrix(rep(0, m), nrow = m)
# setting
zero_p = matrix(rep(0, p), ncol = 1)
zero_m = matrix(rep(0, m), ncol = 1)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
one_p = matrix(rep(1, p), ncol = 1)
one_m = matrix(rep(1, m), ncol = 1)
I_p = matrix(diag(rep(1, p)), nrow = p)
# design matrix for Constraints
Aeq1 = matrix(c(1, t(zero_p), t(zero_m)), nrow = 1)
Aeq2 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, I_p, zero_pm),
c(0, t(zero_p), t(zero_m)))
Aeq3 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, zero_pp, t(Aeq)),
c(0, t(zero_p), t(zero_m)))
Aeq4 = rbind(0, -t(X)%*%y, 0)
Aeq5 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(one_p, zero_pp, zero_pm),
c(0, t(zero_p), t(zero_m)))
# solve
target = Variable(1 + p + m)
constraints = list(Aeq2 %*% target == Aeq3 %*% target,
Aeq2 %*% target <= Aeq4 + Aeq5 %*% target,
Aeq2 %*% target >= Aeq4 - Aeq5 %*% target,
Aeq1 %*% target >= 0)
objective = Minimize(Aeq1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
# result
target = result$getValue(target)
rho_min = target[1, ]
z = target[2:(1+p), ,drop=F]
lambda = target[(p+2):nrow(target), ,drop=F]
rho_min; z; lambda
t(Aeq)
# rho_min에서는 모든 부등조건을 만족
idx1 = which((-t(X) %*% y + rho_min * one_p) <= t(Aeq) %*% lambda)
idx2 = which((-t(X) %*% y - rho_min * one_p) >= t(Aeq) %*% lambda)
activeset = c(idx1, idx2)
sort(activeset)
### 1. 이건 경계에 있는 predictor를 바로 activeset 지정 -> 이건 아닌듯!
idx1 = which(abs((-t(X) %*% y + rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
idx2 = which(abs((-t(X) %*% y - rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
activeset = union(idx1, idx2)
sort(activeset)
### 2. violation check
# find new_lambda corresponding to decreased rho(아주 작게 감소된 rho에 대해 violation을 새로 체크)
new_rho = rho_min - 1e-4 # rho is decreasing direction
target = Variable(1 + m)
Amat1 = matrix(c(rep(0, m), 1), nrow = 1)
Amat = rbind(cbind(t(Aeq), one_p), cbind(-t(Aeq), one_p))
bmat = rbind(-t(X) %*% y + 2 * new_rho * one_p, t(X) %*% y + 2 * new_rho * one_p)
constraints = list(Amat %*% target <= bmat,
Amat1 %*% target <= new_rho)
objective = Maximize(Amat1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
z = result$getValue(target)[m+1, ]
new_lambda = result$getValue(target)[1:m, , drop=F]
# 새로운 rho, lambda에 대해 부등조건을 만족하지 않는(범위를 벗어나는) predictor를 찾는다
idx1 = which((-t(X) %*% y + new_rho * one_p) <= t(Aeq) %*% new_lambda)
idx2 = which((-t(X) %*% y - new_rho * one_p) >= t(Aeq) %*% new_lambda)
activeset = c(idx1, idx2)
sort(activeset) # 최종 active set
# 3. linear combination
activeset = c()
for(i in 1:m) {
idx1 = which(abs(((-t(X) %*% y + rho_min * one_p) - t(Aeq)[, -i, drop=F] %*%
lambda[-i, ,drop=F]) / t(Aeq)[, i] - lambda[i, ]) < 1e-4)
idx2 = which(abs(((-t(X) %*% y - rho_min * one_p) - t(Aeq)[, -i, drop=F] %*%
lambda[-i, ,drop=F]) / t(Aeq)[, i] - lambda[i, ]) < 1e-4)
# print(c(idx1, idx2))
# if(length(activeset) > 0) activeset = c(idx1, idx2)
# activeset = intersect(activeset, c(idx1, idx2))
activeset = union(activeset, c(idx1, idx2))
}
sort(activeset)
rm(list=ls())
gc()
set.seed(520)
if(!require("CVXR")) install.packages("CVXR")
library("CVXR")
# setting
n = 100
p = 5
m = 2
# data
X = matrix(rnorm(n*p), nrow = n)
X.m = apply(X, 2, mean)
X.m = matrix(X.m, nrow = n, ncol = p, byrow = T)
X = X - X.m
true_b = rep(1, p)
y = X %*% true_b + rnorm(n)
y = y - mean(y)
# constraints
# Aeq = matrix(sample(seq(-1, 2, by = 1), m * p, replace = T), nrow = m)
Aeq = matrix(sample(c(-2, -1, 1, 2), m * p, replace = T), nrow = m)
# Aeq = matrix(c(1,1,0,
# -1,0,1,
# -1,-1,1), nrow = m, byrow = T)
beq = matrix(rep(0, m), nrow = m)
# setting
zero_p = matrix(rep(0, p), ncol = 1)
zero_m = matrix(rep(0, m), ncol = 1)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
one_p = matrix(rep(1, p), ncol = 1)
one_m = matrix(rep(1, m), ncol = 1)
I_p = matrix(diag(rep(1, p)), nrow = p)
# design matrix for Constraints
Aeq1 = matrix(c(1, t(zero_p), t(zero_m)), nrow = 1)
Aeq2 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, I_p, zero_pm),
c(0, t(zero_p), t(zero_m)))
Aeq3 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(zero_p, zero_pp, t(Aeq)),
c(0, t(zero_p), t(zero_m)))
Aeq4 = rbind(0, -t(X)%*%y, 0)
Aeq5 = rbind(c(0, t(zero_p), t(zero_m)),
cbind(one_p, zero_pp, zero_pm),
c(0, t(zero_p), t(zero_m)))
# solve
target = Variable(1 + p + m)
constraints = list(Aeq2 %*% target == Aeq3 %*% target,
Aeq2 %*% target <= Aeq4 + Aeq5 %*% target,
Aeq2 %*% target >= Aeq4 - Aeq5 %*% target,
Aeq1 %*% target >= 0)
objective = Minimize(Aeq1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
# result
target = result$getValue(target)
rho_min = target[1, ]
z = target[2:(1+p), ,drop=F]
lambda = target[(p+2):nrow(target), ,drop=F]
rho_min; z; lambda
t(Aeq)
idx1 = which(abs((-t(X) %*% y + rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
idx2 = which(abs((-t(X) %*% y - rho_min * one_p) - t(Aeq) %*% lambda) <= 1e-4)
activeset = union(idx1, idx2)
sort(activeset)
# plot
l1 = seq(-100, 200, length.out = 1000)
l2 = seq(-100, 200, length.out = 1000)
# rho_min = rho_min - 100
y_plus = function(l1, i) (-t(X) %*% y + rho_min * one_p)[i, ] / t(Aeq)[i ,2] - (l1 * t(Aeq)[i ,1]) / t(Aeq)[i ,2]
y_minus = function(l1, i) (-t(X) %*% y - rho_min * one_p)[i, ] / t(Aeq)[i ,2] - (l1 * t(Aeq)[i ,1]) / t(Aeq)[i ,2]
plot(l1, l2, ylab = "", type = "n", col = 1)
points(lambda[1, ], lambda[2, ], col = p+1)
for(i in 1:p) lines(l1, y_plus(l1, i), ylab = "", col = i)
for(i in 1:p) lines(l1, y_minus(l1, i), ylab = "", col = i)
rm(list = ls())
gc()
################################
# JUST FOR ORDINARY REGRESSION #
################################
#
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/conlasso_eq/src")
source("conlasso_init.R")
#
set.seed(520)
### setting --------------------------------------------------
# dimension
n = 100
p = 10
m = 5
# data
X = matrix(rnorm(n*p), nrow = n)
X.m = apply(X, 2, mean)
X.m = matrix(X.m, nrow = n, ncol = p, byrow = T)
X = X - X.m
true_b = rep(1, p)
y = X %*% true_b + rnorm(n)
y = y - mean(y)
n = dim(X)[1]
p = dim(X)[2]
### equality constraints
# Aeq = matrix(rnorm(m*p, 0, 1), nrow = m)
Aeq = matrix(runif(m*p, min = -1, max = 2), nrow = m)
beq = matrix(rep(0, m), nrow = m)
# penalty weight*****(NOT USED)
penwt = rep(1, p) # 20-element Array{Frhoat64,1}
# variable definition
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
beta_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
rho_path = rep(0, maxiters) # tuning parameter
objval_path = rep(0, maxiters) # objective value
# violation_path = rep(Inf, maxiters)
### initialization --------------------------------------------------
H = t(X) %*% X
# find the maximum ρ and corresponding lambda (starting value)
l = path_init(X, y, Aeq, beq) # no inequality constraints
rho_path[1] = l$rho_max
lambda_patheq[, 1] = l$lambda_max
# subgradient for init_beta = 0
beta_path[, 1] = 0
resid = y - X %*% beta_path[, 1]
subgrad = (-t(X) %*% resid - t(Aeq) %*% lambda_patheq[ ,1]) / rho_path[1]
# loss value
objval_path[1] = sum((y - X %*% beta_path[ ,1])^2) + rho_path[1] * sum(abs(beta_path[1]))
# active set
active_set = rep(F, p)
active_set[l$activeset] = T
num_active = sum(active_set)
### main path following algorithm -------------------------------------------
for(k in 2:maxiters) {
### find direction
H = t(X) %*% X
M = rbind(cbind(H[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], matrix(rep(0, m*m), nrow = m)))
S = rbind(subgrad[active_set, , drop=F], matrix(rep(0, m), ncol = 1))
if(min(eigen(M)$values) > 0) {
b_l = solve(M, S)
} else {
b_l = MASS::ginv(M) %*% S
}
delta_b = b_l[1:num_active, ,drop=F]
delta_l = b_l[(num_active+1):nrow(b_l), ,drop=F]
### find delta_rho
delta_rho_vec = c()
# 1. active -> inactive (== subgradient rule check)
nonzero_active_beta = which(active_set)[which(beta_path[active_set, k-1] != 0)]
# predictor have potential to shrink 0
sub_mismatch = sign(beta_path[nonzero_active_beta, k-1]) * sign(delta_b[which(beta_path[active_set, k-1] != 0), ])
if(any(sub_mismatch == 1)) {
delta_rho_sub_tmp = beta_path[nonzero_active_beta[which(sub_mismatch == 1)], k-1] /
delta_b[which(beta_path[active_set, k-1] != 0), ][which(sub_mismatch == 1)]
delta_rho = min(delta_rho_sub_tmp)
delta_rho_vec = c(delta_rho_vec, delta_rho)
# predictor shrink to zero
sub_viol = which(active_set)[which(beta_path[which(active_set), k-1] / delta_b == delta_rho)]
} else {
delta_rho_vec = c(delta_rho_vec, -1)
}
# 2. dual feasibility & KKT - stationarity condition
# for not active set
if(sum(active_set) != p) { # if all predictors are activated, do not run opt problem
delta = Variable(1)
constraints = list(t(X[, !active_set]) %*% (y - X[, active_set] %*% (beta_path[active_set, k-1] - delta * delta_b)) +
t(Aeq[, !active_set]) %*% (lambda_patheq[, k-1] - delta * delta_l)
<= (rho_path[k-1] - delta) * matrix(rep(1, sum(!active_set)), ncol = 1),
t(X[, !active_set]) %*% (y - X[, active_set] %*% (beta_path[active_set, k-1] - delta * delta_b)) +
t(Aeq[, !active_set]) %*% (lambda_patheq[, k-1] - delta * delta_l)
>= -(rho_path[k-1] - delta) * matrix(rep(1, sum(!active_set)), ncol = 1),
delta >= 0)
objective = Maximize(delta)
problem = Problem(objective, constraints)
result = solve(problem)
kkt_viol_to_active = c()
if(is.na(result$getValue(delta))) {
delta_rho_vec = c(delta_rho_vec, -1)
# predictors which cannot satisfy KKT condition
kkt_viol_to_active1 = which(t(X[, !active_set]) %*% (y - X[, active_set] %*% beta_path[active_set, k-1]) +
t(Aeq[, !active_set]) %*% lambda_patheq[, k-1] >
rho_path[k-1] * matrix(rep(1, sum(!active_set)), ncol = 1))
kkt_viol_to_active2 = which(t(X[, !active_set]) %*% (y - X[, active_set] %*% beta_path[active_set, k-1]) +
t(Aeq[, !active_set]) %*% lambda_patheq[, k-1] <
- rho_path[k-1] * matrix(rep(1, sum(!active_set)), ncol = 1))
kkt_viol_to_active = sort(union(kkt_viol_to_active1, kkt_viol_to_active2)) # next added predictor
} else {
delta_rho_vec = c(delta_rho_vec, result$getValue(delta))
# predictor on boundary(for update active set) -> update for active_set
delta_rho_kkt_tmp = result$getValue(delta)
kkt_viol1 = which(abs(t(X[, !active_set]) %*% (y - X[, active_set] %*% (beta_path[active_set, k-1] - delta_rho_kkt_tmp * delta_b)) +
t(Aeq[, !active_set]) %*% (lambda_patheq[, k-1] - delta_rho_kkt_tmp * delta_l) -
(rho_path[k-1] - delta_rho_kkt_tmp) * matrix(rep(1, sum(!active_set)), ncol = 1)) <= 1e-6)
kkt_viol2 = which(abs(t(X[, !active_set]) %*% (y - X[, active_set] %*% (beta_path[active_set, k-1] - delta_rho_kkt_tmp * delta_b)) +
t(Aeq[, !active_set]) %*% (lambda_patheq[, k-1] - delta_rho_kkt_tmp * delta_l) +
(rho_path[k-1] - delta_rho_kkt_tmp) * matrix(rep(1, sum(!active_set)), ncol = 1)) <= 1e-6)
kkt_viol = sort(union(kkt_viol1, kkt_viol2)) # next added predictor
}
} else {
delta_rho_vec = c(delta_rho_vec, -1)
}
### terminate checking (rho becomes 0)
if(any(delta_rho_vec > 0)) {
if(min(delta_rho_vec[delta_rho_vec > 0]) > rho_path[k-1]) {
delta_rho = rho_path[k-1]
rho_path[k] = rho_path[k-1] - delta_rho
beta_path[active_set, k] = beta_path[active_set, k-1, drop=F] - delta_rho * delta_b
objval_path[k] = sum((y - X %*% beta_path[ ,k])^2) + rho_path[k] * sum(abs(beta_path[k]))
lambda_patheq[, k] = lambda_patheq[, k-1] - delta_rho * delta_l
break
}
}
### choose delta_rho
# 1. KKT condition is only violated
if(delta_rho_vec[1] < 0 & delta_rho_vec[2] > 0) {
delta_rho = delta_rho_vec[2]
min_idx = 2
# 2. subgradient rule is only violated
} else if(delta_rho_vec[1] > 0 & delta_rho_vec[2] < 0){
delta_rho = delta_rho_vec[1]
min_idx = 1
# 3. choose first violated rule
} else if(delta_rho_vec[1] > 0 & delta_rho_vec[2] > 0){
delta_rho = min(delta_rho_vec)
min_idx = which.min(delta_rho_vec)
# 4. there is no candidates for delta_rho
} else if(delta_rho_vec[1] < 0 & delta_rho_vec[2] < 0){
if(length(kkt_viol_to_active) > 0) { # if we need to change active set
rho_path[k] = rho_path[k-1]
beta_path[active_set, k] = beta_path[active_set, k-1, drop=F]
objval_path[k] = sum((y - X %*% beta_path[ ,k])^2) + rho_path[k] * sum(abs(beta_path[k]))
lambda_patheq[, k] = lambda_patheq[, k-1]
active_set[which(!active_set)[kkt_viol_to_active]] = T
num_active = sum(active_set)
next
} else {
### terminate algorithm (no event is upcoming)
delta_rho = rho_path[k-1] # make rho to zero
rho_path[k] = rho_path[k-1] - delta_rho
beta_path[active_set, k] = beta_path[active_set, k-1, drop=F] - delta_rho * delta_b
objval_path[k] = sum((y - X %*% beta_path[ ,k])^2) + rho_path[k] * sum(abs(beta_path[k]))
lambda_patheq[, k] = lambda_patheq[, k-1] - delta_rho * delta_l
break
}
}
### updates
rho_path[k] = rho_path[k-1] - delta_rho
beta_path[active_set, k] = beta_path[active_set, k-1, drop=F] - delta_rho * delta_b
objval_path[k] = sum((y - X %*% beta_path[ ,k])^2) + rho_path[k] * sum(abs(beta_path[k]))
lambda_patheq[, k] = lambda_patheq[, k-1] - delta_rho * delta_l
# case 1) subgradient rule is violated
if(min_idx == 1) {
active_set[sub_viol] = F
# case 2) KKT condition is violated
} else if(min_idx == 2) {
active_set[which(!active_set)[kkt_viol]] = T
}
if(length(kkt_viol_to_active) > 0) {
active_set[which(!active_set)[kkt_viol_to_active]] = T
}
num_active = sum(active_set)
}
# result
rho_path[1:k]
beta_path[, 1:k]
lambda_patheq[, 1:k]
objval_path[1:k]
# equality constraint check
sum(abs(Aeq %*% beta_path[, k])) <= 1e-6
# plot
# 1. by sum(abs(beta))
par(mfrow=c(1,1))
plot(apply(abs(beta_path[, 1:k]), 2, sum), rep(0, k), type = "l", col = 1, lwd = 1,
xlim = c(0, sum(abs(beta_path[, k]))), ylim = c(min(beta_path[, 1:k]), max(beta_path[, 1:k])),
xlab = "sum(abs(beta))", ylab = "beta coef", main = "beta coef path(by sum(abs(beta)))")
for(i in 1:p) lines(apply(abs(beta_path[, 1:k]), 2, sum), beta_path[i, 1:k], type = "l", col = i+1, lwd = 2)
# 2. by step
par(mfrow=c(1,1))
plot(seq(1, k), rep(0, k), type = "l", col = 1, lwd = 1,
xlim = c(1, k), ylim = c(min(beta_path[, 1:k]), max(beta_path[, 1:k])),
xlab = "steps", ylab = "beta coef", main = "beta coef path(by step)")
for(i in 1:p) lines(seq(1, k), beta_path[i, 1:k], type = "l", col = i+1, lwd = 2)
