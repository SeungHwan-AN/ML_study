{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus scaled form ADMM \n",
    "### using Gradient Descent  and Stopping Criteria\n",
    "    code without mpi and slaves but this code works in a similiar way "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(!require(data.table)) install.packages('data.table')\n",
    "require(data.table)\n",
    "\n",
    "# parameter setting\n",
    "# here must be added thresholds for stopping criteria\n",
    "\n",
    "# 1.\n",
    "k = 10 # = number of slaves, or blocks?, or partitioned parts of whole data\n",
    "n = 100\n",
    "p = 10\n",
    "eta = 0.01 # learning rate\n",
    "lo = 10\n",
    "epochs = 100\n",
    "iterations = 100\n",
    "# threshold\n",
    "e_abs = 1\n",
    "e_rel = 0.001\n",
    "# running_time = c() # for saveing running time\n",
    "\n",
    "# 2. \n",
    "# beta for slaves\n",
    "local_beta = list()\n",
    "local_dual = list()\n",
    "for(i in 1:k)\n",
    "{\n",
    "  set.seed(i * 520)\n",
    "  local_beta[[i]] = rnorm(p)\n",
    "  set.seed(i * 960)\n",
    "  local_dual[[i]] = rnorm(p)\n",
    "}\n",
    "\n",
    "# 3.\n",
    "true_beta = c(rep(1,3), rep(0,p-3))\n",
    "set.seed(960520)\n",
    "global_beta = matrix(rnorm(p), p, 1)\n",
    "\n",
    "# global objects list for broadcasting\n",
    "global_obj = list(k = k, n = n, p = p, eta = eta, lo = lo, iterations = iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. stopping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopping criteria\n",
    "# 1.for pri and dual variables\n",
    "e_pri_fun = function(p, e_abs, e_rel, x, z) # we didn't used c in constraint at consensus problem\n",
    "{\n",
    "  x_mat = matrix(numeric(0), p, 0)\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    x_mat = cbind(x_mat, x[[i]])\n",
    "  }\n",
    "  return(sqrt(p) * e_abs + e_rel * max(norm(x_mat, \"F\"), norm(z, \"F\")))\n",
    "}\n",
    "e_dual_fun = function(p, e_abs, e_rel, u)\n",
    "{\n",
    "  u_mat = matrix(numeric(0), p, 0)\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    u_mat = cbind(u_mat, u[[i]])\n",
    "  }\n",
    "  return(sqrt(p) * e_abs + e_rel * norm(u_mat, \"F\"))\n",
    "}\n",
    "\n",
    "# 2. for loss criteria\n",
    "loss_function = function(beta)\n",
    "{\n",
    "  loss = 0\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    data = as.matrix(fread(file = paste('C:/Users/dpelt/r_default/admm/admm_data/data', i, '.csv', sep=\"\"), header = T))\n",
    "    x = data[ ,1:p]\n",
    "    y = data[ ,(p + 1)]\n",
    "    loss = loss - t(y) %*% x %*% beta + colSums(log(1 + exp(x %*% beta)))\n",
    "  }\n",
    "  return(loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "for(i in 1:k)\n",
    "{\n",
    "  set.seed(i)\n",
    "  x = matrix(rnorm(n * p), n , p)\n",
    "  y = rbinom(n, size = 1, prob = 1 / (1 + exp(-x %*% true_beta)))\n",
    "  fwrite(cbind(x,y), file = paste('C:/Users/dpelt/r_default/admm/admm_data/data', i, '.csv', sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. slave function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slave function\n",
    "slavefunction_argmin_computing = function(data, beta, b, dual)\n",
    "{\n",
    "  maxiter = 5000\n",
    "  x = data[, 1:global_obj$p]\n",
    "  y = as.matrix(data[, (global_obj$p+1)])\n",
    "  # limited by maxiter\n",
    "  for(i in 1:maxiter)\n",
    "  {\n",
    "    grad = - matrix((t(y) %*% x) / global_obj$n, global_obj$p, 1) + (t(x) %*% (1 / (1 + exp(- x %*% b)))) / global_obj$n +\n",
    "      matrix(global_obj$lo * (b - global_beta - dual), global_obj$p, 1)\n",
    "    b = b - global_obj$eta * grad\n",
    "    # if(i %% 10 == 0) cat(grad[1:10], '\\n')\n",
    "    # stopping criteria\n",
    "    if(norm(grad, \"F\") < 1e-6) break\n",
    "  }\n",
    "    \n",
    "  # not limited in iteration number\n",
    "  # m = 1\n",
    "  # while(T)\n",
    "  # {\n",
    "  #   # not divided by n\n",
    "  #   grad = - matrix((t(y) %*% x) / global_obj$n, global_obj$p, 1) + (t(x) %*% (1 / (1 + exp(- x %*% b)))) / global_obj$n +\n",
    "  #     matrix(global_obj$lo * (b - global_beta - dual), global_obj$p, 1)\n",
    "  #   b = b - global_obj$eta * grad\n",
    "  #   # if(m %% 10 == 0) cat(grad[1:10], '\\n')\n",
    "  #   # stopping criteria\n",
    "  #   if(norm(grad, \"F\") < 1e-6) break\n",
    "  #   # m = m + 1\n",
    "  # }\n",
    "  return(b)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. working part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_time = as.numeric(format(Sys.time(), \"%s\"))\n",
    "for(t in 1:epochs)\n",
    "{\n",
    "  # like slave working\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    b = local_beta[[i]]\n",
    "    dual = local_dual[[i]]\n",
    "    data = as.matrix(fread(file = paste('C:/Users/dpelt/r_default/admm/admm_data/data', i, '.csv', sep=\"\"), header = T))\n",
    "    local_beta[[i]] = slavefunction_argmin_computing(data, global_beta, b, dual)\n",
    "  }\n",
    "    \n",
    "  # global beta update\n",
    "  sum = rep(0, p)\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    sum = sum + local_beta[[i]] + local_dual[[i]]\n",
    "  }\n",
    "  old_beta = global_beta\n",
    "  global_beta = sum / k\n",
    "    \n",
    "  # dual variables update\n",
    "  for(i in 1:k)\n",
    "  {\n",
    "    local_dual[[i]] = local_dual[[i]] + local_beta[[i]] - global_beta\n",
    "  }\n",
    "  # running_time = c(running_time, as.numeric(format(Sys.time(), \"%s\")) - initial_time)\n",
    "  fwrite(as.matrix(global_beta), file = paste('C:/Users/dpelt/r_default/admm/beta2/beta2_', t, '.csv', sep=\"\"))\n",
    "    \n",
    "  # check stopping criteria\n",
    "  # 1. using optimaltiy condition\n",
    "  # e_pri = e_pri_fun(p, e_abs, e_rel, local_beta, global_beta)\n",
    "  # e_dual = e_dual_fun(p, e_abs, e_rel, local_dual)\n",
    "  # b_mat = matrix(numeric(0), p, 0)\n",
    "  # for(i in 1:k)\n",
    "  # {\n",
    "  #   b_mat = cbind(b_mat, local_beta[[i]])\n",
    "  # }\n",
    "  # r = b_mat - global_beta %*% matrix(rep(1, k), 1, k)\n",
    "  # s = as.matrix(global_obj$lo * (old_beta - global_beta))\n",
    "  # if(t %% 5 == 0) cat('1:', norm(r, \"F\"), '2:', norm(s, 'F'), '\\n')\n",
    "  # if(norm((r), \"F\") < e_pri && norm((s), \"F\") < e_dual) break\n",
    "    \n",
    "  # 2. using loss \n",
    "  cat('loss:', loss_function(global_beta), '\\n')\n",
    "  if(t > 1 && loss_function(global_beta) > loss_function(old_beta)) break\n",
    "}\n",
    "# fwrite(as.matrix(running_time), file = paste('C:/Users/dpelt/r_default/admm/running_time.csv', sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. loss ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t - 1\n",
    "# integrating global beta\n",
    "total_beta = matrix(numeric(0), p, 0)\n",
    "for(i in 1:t)\n",
    "{\n",
    "  total_beta = cbind(total_beta, \n",
    "                     as.matrix(fread(file = paste('C:/Users/dpelt/r_default/admm/beta2/beta2_', i, '.csv', sep=\"\"))))\n",
    "}\n",
    "\n",
    "# loss computing\n",
    "loss = rep(0, t)\n",
    "for(i in 1:k)\n",
    "{\n",
    "  data = as.matrix(fread(file = paste('C:/Users/dpelt/r_default/admm/admm_data/data', i, '.csv', sep=\"\"), header = T))\n",
    "  x = data[ ,1:p]\n",
    "  y = data[ ,(p + 1)]\n",
    "  loss = loss - t(y) %*% x %*% total_beta + colSums(log(1 + exp(x %*% total_beta)))\n",
    "}\n",
    "fwrite(as.matrix(loss), file = paste('C:/Users/dpelt/r_default/admm/admm_loss2.csv', sep=\"\"))\n",
    "\n",
    "# save loss~running_time plot\n",
    "# png(file = \"/home/jeon/an/admm/admm_loss_plot2.png\")\n",
    "# running_time = as.matrix(fread(file = '/home/jeon/an/admm/running_time.csv', header = T))\n",
    "# plot(running_time, loss)\n",
    "plot(seq(1,t,1), loss)\n",
    "# dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss plot](https://github.com/SeungHwan-AN/ML_study/blob/master/ADMM/image/loss_plot_without_mpi.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
