### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
### initialization
l = init_OPL_lasso(P, Aeq, beq)
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
#
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
### initialization
l = init_OPL_lasso(P, Aeq, beq)
l
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[1, ] = l$x_init
lambda_path[1, ] = l$max_lambda
lambda_path[1] = l$max_lambda
mu_patheq = l$max_mu
nu_pathineq = l$max_nu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t()))
active_set = l$active_set
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t(nu_pathineq[1, active_set]), 0))
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[1, ] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq = l$max_mu
nu_pathineq = l$max_nu
active_set = l$active_set
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t(nu_pathineq[1, active_set]), 0))
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[1, ] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
x_path[, 1] = l$x_init
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[, 1] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
nu_pathineq[, 1] = l$max_nu
active_set = l$active_setN
active_set = l$active_set
x_path
lambda_path
mu_patheq
nu_pathineq
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t(nu_pathineq[active_set, 1]), 0))
P
cbind(2 * P[active_set, active_set], t(Aeq[, active_set]))
2 * P[active_set, active_set]
cbind(Aeq[, active_set], zero_mm)
cbind(t(nu_pathineq[active_set, 1]), 0)
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t(nu_pathineq[active_set, 1]), t(zero_m)))
subgrad = 2 * P[active_set, active_set] %*% x_path[active_set, 1]
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] + t(Aeq[, active_set]) %*% mu_patheq[1, ]) / lambda_path[1]
t(Aeq[, active_set]) %*% mu_patheq[1, ]
t(Aeq[, active_set])
mu_patheq[1, ]
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] + t(Aeq[, active_set]) %*% mu_patheq[, 1]) / lambda_path[1]
subgrad
subgrad = -(2 * P %*% x_path[, 1] + t(Aeq[, ]) %*% mu_patheq[, 1]) / lambda_path[1]
subgrad
which(active_set)
x_path[, 1]
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] +
t(Aeq[, active_set]) %*% mu_patheq[, 1] + nu_pathineq[active_set, 1]) / lambda_path[1]
subgrad
nu_pathineq[active_set, 1]
subgrad = sign(x_path[active_set, 1])
subgrad
x_path[active_set, 1]
subgrad = sign(x_path[active_set, 1, drop=F])
subgra
subgrad
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m, 0)
x_mu_dir
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
################### initialization #####################
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### get initial x (x_init)
##### solve
# min   sum(abs(beta))
# s.t.  Ax = b
#       x >= 0
#####
x = Variable(p)
constraints = list(Aeq %*% x == beq,
x >= 0)
objective = Minimize(sum(abs(x)))
problem = Problem(objective, constraints)
result = solve(problem)
x_init = result$getValue(x)
x_init[x_init < 1e-4] = 0.0 # for numerical stability
x_init
### conditions check
sum(abs(x_init))
abs(Aeq %*% x_init - beq) < 1e-6
x_init >= 0
### get initial lambda, mu, nu, active_set
# Design matrix
D1 = cbind(1, t(zero_m), t(zero_p))
D2 = cbind(zero_p, t(Aeq), I_pp)
D3 = cbind(one_p, zero_pm, zero_pp)
D4 = cbind(zero_p, zero_pm, I_pp)
# get initial lambda, mu, nu corresponding to x_init
target = Variable(1 + m + p)
constraints = list(2 * P %*% x_init + D2 %*% target <= D3 %*% target, # stationarity
2 * P %*% x_init + D2 %*% target >= - D3 %*% target, # stationarity
D1 %*% target >= 0, # lambda must be positive
D4 %*% target >= zero_p, # dual feasibility
t(D4 %*% target) %*% x_init == 0 # complementary slackness
)
objective = Minimize(D1 %*% target)
problem = Problem(objective, constraints)
result = solve(problem)
# result$getValue(target)
max_lambda = result$getValue(target)[1]
max_mu = result$getValue(target)[2:(1+m), , drop=F]
max_nu = result$getValue(target)[(m+2):nrow(result$getValue(target)), , drop=F]
max_nu[max_nu < 1e-4] = 0.0 # for numerical stability
x_init; max_lambda; max_mu; max_nu
# active_set
active_set = rep(F, p)
active_set[which(x_init != 0)] = T
active_set
sum(active_set)
nu_pathineq[active_set, 1]
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[, 1] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
nu_pathineq[, 1] = l$max_nu
active_set = l$active_set
### get direction for x and mu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm),
cbind(t(nu_pathineq[active_set, 1]), t(zero_m)))
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] +
t(Aeq[, active_set]) %*% mu_patheq[, 1]) / lambda_path[1]
# active set의 subgradient는 항상 반드시 1
# but 1이 아닌 subgradient 존재...why?
subgrad = sign(x_path[active_set, 1, drop=F])
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m, 0)
cbind(t(nu_pathineq[active_set, 1]), t(zero_m))
### get direction for x and mu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm))
H
nu[active_set, 1]
nu_pathineq[active_set, 1]
nu_pathineq[!active_set, 1]
x_path[!active_set, 1]
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(30)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[, 1] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
nu_pathineq[, 1] = l$max_nu
active_set = l$active_set
### get direction for x and mu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm))
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] +
t(Aeq[, active_set]) %*% mu_patheq[, 1]) / lambda_path[1]
subgrad = sign(x_path[active_set, 1, drop=F])
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m, 0)
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m)
x_mu_dir
MASS::ginv(H)
H
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(11)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[, 1] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
nu_pathineq[, 1] = l$max_nu
active_set = l$active_set
### get direction for x and mu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm))
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] +
t(Aeq[, active_set]) %*% mu_patheq[, 1]) / lambda_path[1]
# active set의 subgradient는 항상 반드시 1
# but 1이 아닌 subgradient 존재...why?
subgrad = sign(x_path[active_set, 1, drop=F])
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m)
x_mu_dir
nu_pathineq[,1]
nu_pathineq[active_set,1]
nu_pathineq[!active_set,1]
subgrad = -(2 * P %*% x_path[, 1] + t(Aeq[, ]) %*% mu_patheq[, 1]) / lambda_path[1]
subgrad
rm(list=ls())
gc()
# choose seed: 3, 7, 11, 22, 30,
set.seed(11)
if(!require("CVXR")) install.packages("CVXR")
library(CVXR)
setwd("C:/Users/dpelt/OneDrive - 서울시립대학교/Documents/GitHub/ML_study/OPL")
source("OPL_lasso_init3.R")
### dimension
n = 100
p = 10
m = 5
### data setting
X = matrix(rnorm(n*p), nrow = n)
P = t(X) %*% X
P.m = matrix(apply(P, 2, mean), nrow = p, ncol = p, byrow = T)
P = P - P.m # normalize data
Aeq = matrix(runif(m*p, min = -2, max = 2), nrow = m)
beq = matrix(runif(m, min = -5, max = 5), nrow = m)
#
zero_m = matrix(rep(0, m), nrow = m)
zero_p = matrix(rep(0, p), nrow = p)
one_p = matrix(rep(1, p), nrow = p)
one_m = matrix(rep(1, m), nrow = m)
I_pp = diag(1, p)
zero_pm = matrix(rep(0, p*m), nrow = p)
zero_pp = matrix(rep(0, p*p), nrow = p)
zero_mm = matrix(rep(0, m*m), nrow = m)
### path storage
neq = dim(Aeq)[1]
maxiters = 5 * p # max number of path segments to consider
x_path = matrix(rep(0, p * maxiters), nrow = p)
lambda_path = rep(0, maxiters) # tuning parameter
mu_patheq = matrix(rep(0, neq * maxiters), nrow = neq) # dual variables for equality
nu_pathineq = matrix(rep(0, p * maxiters), nrow = p)
objval_path = rep(0, maxiters) # objective value
### initialization
l = init_OPL_lasso(P, Aeq, beq)
x_path[, 1] = l$x_init
lambda_path[1] = l$max_lambda
mu_patheq[, 1] = l$max_mu
nu_pathineq[, 1] = l$max_nu
active_set = l$active_set
### get direction for x and mu
H = rbind(cbind(2 * P[active_set, active_set], t(Aeq[, active_set])),
cbind(Aeq[, active_set], zero_mm))
subgrad = -(2 * P[active_set, active_set] %*% x_path[active_set, 1] +
t(Aeq[, active_set]) %*% mu_patheq[, 1]) / lambda_path[1]
# active set의 subgradient는 항상 반드시 1
# but 1이 아닌 subgradient 존재...why?
subgrad = -(2 * P %*% x_path[, 1] + t(Aeq[, ]) %*% mu_patheq[, 1]) / lambda_path[1]
subgrad
subgrad = sign(x_path[active_set, 1, drop=F])
x_mu_dir = MASS::ginv(H) %*% rbind(subgrad, zero_m)
x_mu_dir
which(apply(array, margin, ...))
which(active_set)
